{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eea446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run setup_imports to enable importing from src/\n",
    "%run ./setup_imports.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f9035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit\n",
    "from qonscious.constraints import PackedCHSHTest\n",
    "from qonscious.policies import MinimumAcceptableValue\n",
    "from qonscious.core import IBMSamplerAdapter\n",
    "from qonscious.core import executor\n",
    "from dotenv import load_dotenv \n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pli_plus = QuantumCircuit(2, 2)\n",
    "pli_plus.h(0)\n",
    "pli_plus.cx(0, 1)\n",
    "pli_plus.measure([0, 1], [0, 1])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637adc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = 100  # \n",
    "delay_between_reps = 60 * 5  # Every five minutes\n",
    "introspection_shots = 1024\n",
    "main_circuit_shots = 1024\n",
    "entanglement_threshold = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backend():\n",
    "  load_dotenv()\n",
    "  ibm_token = os.getenv(\"IBM_QUANTUM_TOKEN\")\n",
    "  service = QiskitRuntimeService(channel=\"ibm_quantum_platform\", token=ibm_token)\n",
    "  return service.least_busy(operational=True, simulator=False)\n",
    "\n",
    "ibm_backend_adapter = IBMSamplerAdapter(get_backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f0a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_pass(backend_adapter, introspection_result):\n",
    "    entry = {}\n",
    "    print(f\"Entanglement passed with score: {introspection_result['CHSH_score']}\")\n",
    "    entry['entanglement_score'] = introspection_result['CHSH_score']\n",
    "    entry['introspection'] = introspection_result\n",
    "    entry['execution'] = backend_adapter.run(pli_plus, shots=main_circuit_shots)\n",
    "    return entry\n",
    "\n",
    "def on_fail(backend_adapter, introspection_result):\n",
    "    entry = {}\n",
    "    print(f\"Skipping main circuit - entanglement score was {introspection_result['CHSH_score']}\")\n",
    "    entry['entanglement_score'] = introspection_result['CHSH_score']\n",
    "    entry['introspection'] = introspection_result\n",
    "    return entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "constraint = PackedCHSHTest(policy=MinimumAcceptableValue(entanglement_threshold))\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(reps):\n",
    "    print(f\"{i+1}. Running introspection + conditional execution\")\n",
    "    entry =  executor.run_conditionally(\n",
    "        backend_adapter=ibm_backend_adapter,\n",
    "        constraint=constraint,\n",
    "        on_pass=on_pass,\n",
    "        on_fail=on_fail,\n",
    "        shots=introspection_shots\n",
    "    )\n",
    "    results.append(entry)\n",
    "    if i < reps - 1:\n",
    "        time.sleep(delay_between_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0064e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "chsh_scores = [entry[\"introspection\"][\"CHSH_score\"] for entry in results]\n",
    "plt.figure()\n",
    "plt.plot(range(len(results)), chsh_scores, marker='o')\n",
    "plt.title(\"CHSH Score Over Repetitions\")\n",
    "plt.xlabel(\"Run Index\")\n",
    "plt.ylabel(\"CHSH Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_utc(s):\n",
    "    return datetime.fromisoformat(s.replace(\"Z\", \"+00:00\"))\n",
    "\n",
    "durations = [\n",
    "    (parse_utc(entry[\"execution\"][\"timestamps\"][\"running\"]) -\n",
    "     parse_utc(entry[\"introspection\"][\"timestamps\"][\"finished\"])).total_seconds()\n",
    "    for entry in results\n",
    "]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(durations)), durations, marker='o', color='orange')\n",
    "plt.title(\"Total Delay from Introspection End to Execution Start\")\n",
    "plt.xlabel(\"Run Index\")\n",
    "plt.ylabel(\"Duration (s)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2439b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_plus_fidelity(counts):\n",
    "    shots = sum(counts.values())\n",
    "    prob_00 = counts.get(\"00\", 0) / shots\n",
    "    prob_11 = counts.get(\"11\", 0) / shots\n",
    "    # For ideal \\Phi^+, the off-diagonal terms contribute too, but from counts only, we approximate fidelity\n",
    "    return prob_00 + prob_11  # coarse classical fidelity estimate\n",
    "\n",
    "fidelities = [phi_plus_fidelity(entry[\"execution\"][\"counts\"]) for entry in results]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(fidelities)), fidelities, marker='o', color='green')\n",
    "plt.title(\"Approximate Fidelity to Phi+ State\")\n",
    "plt.xlabel(\"Run Index\")\n",
    "plt.ylabel(\"Fidelity Estimate\")\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save experiment data in a tabular summary\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "csv_filename = f\"experiment_summary_{timestamp}.csv\"\n",
    "\n",
    "df = pd.DataFrame([{\n",
    "    'introspection_created': r.get('introspection', {}).get('timestamps', {}).get('created'),\n",
    "    'introspection_running': r.get('introspection', {}).get('timestamps', {}).get('running'),\n",
    "    'introspection_finished': r.get('introspection', {}).get('timestamps', {}).get('finished'),\n",
    "    'execution_created': r.get('execution', {}).get('timestamps', {}).get('created'),\n",
    "    'execution_running': r.get('execution', {}).get('timestamps', {}).get('running'),\n",
    "    'execution_finished': r.get('execution', {}).get('timestamps', {}).get('finished'),    \n",
    "    'entanglement_score': r.get('entanglement_score'),\n",
    "    'execution_counts': json.dumps(r.get('execution', {}).get('counts')) if r.get('execution') else None\n",
    "} for r in results])\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
